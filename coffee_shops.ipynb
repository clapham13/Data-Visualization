{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import pylab as pl\n",
    "import requests\n",
    "import shutil \n",
    "import sys\n",
    "import urllib\n",
    "import urllib.request \n",
    "import zipfile \n",
    "%matplotlib inline\n",
    "\n",
    "try:\n",
    "    # For Python 3.0 and later\n",
    "    from urllib.error import HTTPError\n",
    "    from urllib.parse import quote\n",
    "    from urllib.parse import urlencode\n",
    "except ImportError:\n",
    "    # Fall back to Python 2's urllib2 and urllib\n",
    "    from urllib2 import HTTPError\n",
    "    from urllib import quote\n",
    "    from urllib import urlencode\n",
    "    \n",
    "from pandas.io.json import json_normalize\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for accessing the API\n",
    "API_KEY = open('yelp_api.txt', 'r').readlines()[1][:-1] # api stored in seperate .txt file\n",
    "API_HOST = 'https://api.yelp.com'\n",
    "SEARCH_PATH = '/v3/businesses/search'\n",
    "BUSINESS_PATH = '/v3/businesses/'\n",
    "\n",
    "### Search Terms\n",
    "params = {\n",
    "    'term': 'coffee',\n",
    "    'location': 'Clinton Hill, Brooklyn',\n",
    "    'limit':'50'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request(host=API_HOST, path=SEARCH_PATH, api_key=API_KEY, url_params=params):\n",
    "    \"\"\"Given your API_KEY, send a GET request to the API.\n",
    "    Args:\n",
    "        host (str): The domain host of the API.\n",
    "        path (str): The path of the API after the domain.\n",
    "        API_KEY (str): Your API Key.\n",
    "        url_params (dict): An optional set of query parameters in the request.\n",
    "    Returns:\n",
    "        dict: The JSON response from the request.\n",
    "    Raises:\n",
    "        HTTPError: An error occurs from the HTTP request.\n",
    "    \"\"\"\n",
    "    url_params = url_params or {}\n",
    "    url = '{0}{1}'.format(host, quote(path.encode('utf8')))\n",
    "    headers = {\n",
    "        'Authorization': 'Bearer %s' % api_key,\n",
    "    }\n",
    "\n",
    "    response = requests.request('GET', url, headers=headers, params=url_params)\n",
    "\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(api_key, term, location, categories, offset, price):\n",
    "    \"\"\"Query the Search API by a search term and location.\n",
    "    Args:\n",
    "        term (str): The search term passed to the API.\n",
    "        location (str): The search location passed to the API.\n",
    "    Returns:\n",
    "        dict: The JSON response from the request.\n",
    "    \"\"\"\n",
    "\n",
    "    url_params = {\n",
    "        'term': term.replace(' ', '+'),\n",
    "        'location': location.replace(' ', '+'),\n",
    "        'limit': int(params['limit']),\n",
    "        'offset': offset,\n",
    "        'categories': categories,\n",
    "        'price':price\n",
    "    }\n",
    "    \n",
    "    find_locs = request(API_HOST, SEARCH_PATH, api_key, url_params=url_params)\n",
    "    \n",
    "    return json_normalize(find_locs['businesses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't really need this, but useful for initially analyzing the pulls from yelp\n",
    "def print_pretty_yelp_json(json):\n",
    "    for i in range(len(json['businesses'])):\n",
    "        item = json['businesses'][i] #['alias']\n",
    "\n",
    "        print(' Store Name:',item['name'], '\\n',\n",
    "              'Categories:', [item['categories'][i]['title'] \\\n",
    "                              for i in range(len(item['categories']))], '\\n',\n",
    "              'Latitude:', item['coordinates']['latitude'], '\\n',\n",
    "              'Longitude:', item['coordinates']['longitude'], '\\n',\n",
    "              'City:', item['location']['city'], '\\n',\n",
    "              'Zip Code:', item['location']['zip_code'], '\\n',\n",
    "              'Price:', item['price'],  '\\n',\n",
    "              'Rating:', item['rating'], '\\n',\n",
    "              'Review Count:', item['review_count'], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_coffee(df):\n",
    "    category_list = [[df['categories'][j][i]['title'] \\\n",
    "    for i in range(len(df['categories'][j]))] \\\n",
    "    for j in range(len(df['categories']))]\n",
    "\n",
    "    location = list(zip(df['coordinates.latitude'], \n",
    "                             df['coordinates.longitude']))\n",
    "\n",
    "    columns = ['Store_Name', 'Categories', 'Location', 'City', \n",
    "                   'Zip_Code', 'Price', 'Rating', 'Review_Count']\n",
    "    data = [list(df['name']), category_list, location, list(df['location.city']),\n",
    "                list(df['location.zip_code']), list(df['price']), list(df['rating']), \n",
    "                list(df['review_count'])]\n",
    "\n",
    "\n",
    "    filtered_coffee = pd.DataFrame(data = dict(zip(columns, data)))\n",
    "    filtered_coffee = filtered_coffee[columns]\n",
    "    return filtered_coffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_coffee(search_term='coffee', loc='Brooklyn',category=None, loops=20, price=[1,2,3,4]):\n",
    "    \n",
    "    coffee_shops_df = None\n",
    "    \n",
    "    for i in range(loops):\n",
    "        try:\n",
    "            # max api allows is 50 per pull\n",
    "            coffee_results = search(API_KEY, search_term, loc, category, i*50, price)\n",
    "        except IndexError:\n",
    "            # error raised once no more coffee shops in the area are found.\n",
    "            for j in range(49, -1, -1): \n",
    "                if j == 0:\n",
    "                    break\n",
    "                try:\n",
    "                    coffee_results = search(API_KEY, search_term, loc, category, i*j, price)\n",
    "                except IndexError:\n",
    "                    continue\n",
    "                break\n",
    "            \n",
    "        coffee_results = filtered_coffee(coffee_results)\n",
    "        \n",
    "        if isinstance(coffee_shops_df, pd.DataFrame):\n",
    "            coffee_shops_df = pd.concat([coffee_shops_df, coffee_results])\n",
    "            coffee_shops_df.reset_index(drop=True, inplace=True)\n",
    "        else:\n",
    "            coffee_shops_df = coffee_results\n",
    "            \n",
    "    return coffee_shops_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_to_gpd(df):\n",
    "    geom = df.apply(lambda x: Point(x['Location'][1], x['Location'][0]), axis=1)\n",
    "    geo_df = gpd.GeoDataFrame(df, geometry=geom)\n",
    "    geo_df.crs = {'init' :'epsg:4326'}\n",
    "    return geo_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zillow Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_zillow_map(city):\n",
    "    '''\n",
    "    Takes the name of a city as an arguement, and pulls the file from Zillow's neighborhood website\n",
    "    Returns a geopandas dataframe of the city\n",
    "    '''\n",
    "    \n",
    "    state = cities_to_states[city]\n",
    "\n",
    "    zillow_call = 'https://www.zillowstatic.com/static-neighborhood-boundaries' + \\\n",
    "                  '/LATEST/static-neighborhood-boundaries/shp/' + \\\n",
    "                  'ZillowNeighborhoods-{}.zip'.format(state)\n",
    "\n",
    "    file_name = '{}_shape.zip'.format(state)\n",
    "    city_shp = 'ZillowNeighborhoods-{}.shp'.format(state)\n",
    "\n",
    "    # download the file if it doesn't already exist\n",
    "    if not os.path.exists(city_shp):\n",
    "        # download zip from Zillow website\n",
    "        with urllib.request.urlopen(zillow_call) as response, \\\n",
    "                           open(file_name, 'wb') as out_file:\n",
    "            shutil.copyfileobj(response, out_file)\n",
    "        # extract shapefile into current folder\n",
    "        with zipfile.ZipFile(file_name,\"r\") as zip_ref:\n",
    "            zip_ref.extractall()\n",
    "        # remove unneeded files\n",
    "        os.remove(file_name)\n",
    "\n",
    "    data = gpd.read_file(city_shp)\n",
    "    if city != 'Boston':\n",
    "        data = data[data['City']==city]\n",
    "    elif city == 'Boston':\n",
    "        data = data[(data['City']==city) | (data['City']=='Cambridge') \\\n",
    "                    | (data['City']=='Newton')]\n",
    "        \n",
    "    data.crs = {'init' :'epsg:4326'}\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cities to work with\n",
    "cities_to_states = {'New York':'NY',\n",
    "                    'Los Angeles': 'CA', \n",
    "                    'Chicago':'IL',\n",
    "                    'Dallas': 'TX',\n",
    "                    'Houston':'TX',\n",
    "                    'Washington':'DC',\n",
    "                    'Philadelphia': 'PA',\n",
    "                    'Miami': 'FL',\n",
    "                    'Atlanta': 'GA',\n",
    "                    'Boston':'MA', \n",
    "                    'San Francisco':'CA',\n",
    "                    'Detroit': 'MI',\n",
    "                    'Denver': 'CO',\n",
    "                    'Charlottesville': 'VA',\n",
    "                    'Baltimore': 'MD',\n",
    "                    'Charlotte': 'NC',\n",
    "                    'Pittsburgh': 'PA',\n",
    "                    'Austin': 'TX',\n",
    "                    'Cleveland': 'OH',\n",
    "                    'Columbus': 'OH',\n",
    "                    'Portland': 'OR',\n",
    "                    'New Orleans': 'LA',\n",
    "                    'Salt Lake City': 'UT',\n",
    "                    'Seattle':'WA'}\n",
    "\n",
    "cities = sorted(list(cities_to_states.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cities(cities):\n",
    "    import math\n",
    "    # print maps of all of the cities\n",
    "    ncols = 2\n",
    "    nrows = math.ceil(len(cities)/ncols)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize = (16, 100))\n",
    "    for i in range(len(cities)):\n",
    "        city_gdf = create_zillow_map(cities[i])\n",
    "        ax = plt.subplot(nrows, ncols,i+1)\n",
    "        city_gdf.plot(figsize=(8,8), color='lightblue', edgecolor='k', ax=ax)\n",
    "        ax.set_title(cities[i], fontsize=14, weight='bold')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bringing it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_gdfs(city, loops=20):\n",
    "    \n",
    "    if city == 'Washington':\n",
    "        city_temp = 'Washington, DC'\n",
    "    else:\n",
    "        city_temp = city\n",
    "    \n",
    "    coffee_shops_df = find_coffee(loc=city_temp, loops=loops)\n",
    "    coffee_shops_gdf = pd_to_gpd(coffee_shops_df)\n",
    "    city_map_gdf = create_zillow_map(city)\n",
    "    merged_gdf = gpd.sjoin(coffee_shops_gdf, city_map_gdf, op='within')\n",
    "    \n",
    "    # do some cleaning and group bys\n",
    "    merged_gdf.rename(columns={'City_right':'City'}, inplace=True)\n",
    "    merged_gdf.drop(['index_right', 'City_left'], axis=1, inplace=True)\n",
    "    merged_gdf.reset_index(drop=True, inplace=True)\n",
    "    city_map_gdf.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # central coordinates for neighborhood labels\n",
    "    city_map_gdf['coords'] = city_map_gdf['geometry'].apply(lambda x: x.representative_point().coords[:])\n",
    "    city_map_gdf['coords'] = [coords[0] for coords in city_map_gdf['coords']]\n",
    "    \n",
    "    # add count of coffee shops in each neighborhood to map df\n",
    "    neighborhood_counts = dict(merged_gdf.groupby('Name').count().iloc[:,0])\n",
    "    city_map_gdf['count'] = city_map_gdf.Name.map(neighborhood_counts)\\\n",
    "                                        .fillna(0) \\\n",
    "                                        .astype(int)\n",
    "    \n",
    "    # add mean rating to map df\n",
    "    rating_mean = dict(merged_gdf.groupby('Name').mean()['Rating'])\n",
    "    city_map_gdf['mean_rating'] = city_map_gdf.Name.map(rating_mean)\\\n",
    "                                              .round(3)\n",
    "    \n",
    "    # add mean price to map df\n",
    "    price_map = {'$': 1, '$$': 2, '$$$': 3, '$$$$': 4}\n",
    "    merged_gdf['price_int'] = merged_gdf.Price.map(price_map)\n",
    "    price_mean = dict(merged_gdf.groupby('Name').mean()['price_int'])\n",
    "    city_map_gdf['mean_price'] = city_map_gdf.Name.map(price_mean)\\\n",
    "                                             .round(3)\n",
    "\n",
    "    # add review count to map df\n",
    "    total_reviews = dict(merged_gdf.groupby('Name').mean()['Review_Count'])\n",
    "    city_map_gdf['review_count'] = city_map_gdf.Name.map(total_reviews)\\\n",
    "                                               .fillna(0) \\\n",
    "                                               .astype(int) \n",
    "    \n",
    "    # indentify 'chain' coffee stores as those with > 3 location in a city\n",
    "    # add percentage of stores that are chain for each neighborhood to map df\n",
    "    chain = dict(merged_gdf['Store_Name'].value_counts() > 3)\n",
    "    merged_gdf['chain'] = merged_gdf.Store_Name.map(chain)\n",
    "    pct_chain = dict(merged_gdf.groupby('Name').mean()['chain'])\n",
    "    city_map_gdf['pct_chain'] = city_map_gdf.Name.map(pct_chain)\\\n",
    "                                                 .astype(float)\\\n",
    "                                                 .round(3)\n",
    "     \n",
    "    # identify those shops that only have the category 'Coffee & Tea'\n",
    "    strictly_coffee = [('Coffee & Tea' in cat and len(cat) == 1) or \\\n",
    "                       ('Cafes' in cat and len(cat) == 1) or \\\n",
    "                       ('Coffee Roasteries' in cat and len(cat) == 1) or \\\n",
    "                       ('Coffee & Tea' in cat and 'Cafes' in cat and len(cat) == 2) or \\\n",
    "                       ('Coffee & Tea' in cat and 'Coffee Roasteries' in cat and len(cat) == 2) or \\\n",
    "                       ('Cafes' in cat and 'Coffee Roasteries' in cat and len(cat) == 2) or \\\n",
    "                       ('Coffee & Tea' in cat and 'Cafes' in cat and 'Coffee Roasteries' in cat and len(cat) == 3) \\\n",
    "                       for cat in merged_gdf.Categories.values]\n",
    "    merged_gdf['strictly_coffee'] = strictly_coffee\n",
    "    \n",
    "    # indentifies weather 'Coffee & Tea' is a category (regardless of if there are others)\n",
    "    coffee_is_cat = ['Coffee & Tea' in cat or 'Cafes' in cat or 'Coffee Roasteries' in cat \\\n",
    "                     for cat in merged_gdf.Categories.values]\n",
    "    merged_gdf['coffee_is_cat'] = coffee_is_cat # meow\n",
    "    \n",
    "    # add bool columns for other notable categories\n",
    "    merged_gdf['breakfast_and_brunch'] = ['Breakfast & Brunch' in cat for cat in merged_gdf.Categories.values]\n",
    "    merged_gdf['bakeries'] = ['Bakeries' in cat for cat in merged_gdf.Categories.values]\n",
    "    merged_gdf['diner'] = ['Diner' in cat for cat in merged_gdf.Categories.values]\n",
    "    merged_gdf['deli'] = ['Deli' in cat for cat in merged_gdf.Categories.values]\n",
    "    merged_gdf['ice_cream_and_froyo'] = ['Ice Cream & Frozen Yogurt' in cat for cat in merged_gdf.Categories.values]\n",
    "    merged_gdf['juice_and_smoothie'] = ['Juice Bars & Smoothies' in cat for cat in merged_gdf.Categories.values]\n",
    "    \n",
    "    # identify primary category of shop, and add a categorical column for it\n",
    "    def categorize(x):\n",
    "        '''\n",
    "        fa la la la la\n",
    "        '''\n",
    "        cat_start = x.index.get_loc('chain')\n",
    "        cat_cols  = x[cat_start:]\n",
    "        if cat_cols['chain'] == True:\n",
    "            return 'chain'\n",
    "        elif cat_cols['diner'] == True:\n",
    "            return 'diner'\n",
    "        elif cat_cols['deli'] == True:\n",
    "            return 'deli'\n",
    "        elif cat_cols['ice_cream_and_froyo'] == True:\n",
    "            return 'ice_cream_and_froyo'\n",
    "        elif cat_cols['juice_and_smoothie'] == True:\n",
    "            return 'juice_and_smoothie'\n",
    "        elif cat_cols['bakeries'] == True:\n",
    "            return 'bakeries'\n",
    "        elif cat_cols['breakfast_and_brunch'] == True:\n",
    "            return 'breakfast_and_brunch'\n",
    "        elif cat_cols['strictly_coffee'] == True:\n",
    "            return 'strictly_coffee'\n",
    "        else:\n",
    "            return 'other'       \n",
    "    \n",
    "    merged_gdf['primary_category'] = merged_gdf.apply(lambda x: categorize(x), axis=1)\n",
    "    \n",
    "    # add percentage of our just-defined categories to our map df\n",
    "    cat_start = merged_gdf.columns.get_loc(\"strictly_coffee\")\n",
    "    categories = merged_gdf.columns[cat_start:-1]\n",
    "    for cat in categories:\n",
    "        city_map_gdf['pct_' + str(cat)] = city_map_gdf.Name.map(dict( \\\n",
    "                          merged_gdf.groupby('Name').mean()[cat])).round(3)\n",
    "\n",
    "    return city_map_gdf, merged_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top(city_name, df, count=10):\n",
    "    print('----------------------------------------')\n",
    "    print('Top {} Categories for {}:'.format(count, city_name))\n",
    "    print('-----------------------' + '-' * len(city_name))\n",
    "    print(pd.Series([x for y in df.Categories.values for x in y]).value_counts()[:count])\n",
    "    print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_map(map_gdf, data_gdf, column='count', neighborhood_labels=True):\n",
    "    vmin, vmax = map_gdf[column].min(), map_gdf[column].max()\n",
    "    fig, ax = plt.subplots(1, figsize=(18.2,15.5))\n",
    "    base = map_gdf.plot(ax=ax, column='count', edgecolor='white', \n",
    "                        cmap='copper', vmin=vmin, vmax=vmax, legend=True)\n",
    "    data_gdf.plot(ax=base, marker=\"o\", color='r',\n",
    "                              markersize=10, alpha=0.7)\n",
    "        # add neighborhood labels\n",
    "    if neighborhood_labels == True:\n",
    "        for idx, row in map_gdf.iterrows():\n",
    "            plt.annotate(s=row['Name'], xy=row['coords'], color='white',\n",
    "                         horizontalalignment='center', size=8)\n",
    "    ax.set_title(\"Coffee Shops in \" + str(city), size=20)\n",
    "    plt.show()\n",
    "    \n",
    "#plot_map(city_map_gdf, merged_gdf, 'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'coffee_data/'\n",
    "\n",
    "def save_files(list_of_cities, update_data=False):\n",
    "    for city in list_of_cities:\n",
    "        # if the file exists, and we don't want to update data, skip files already downloaded\n",
    "        # so that we can speed things up.\n",
    "        if not os.path.isdir(path):\n",
    "            os.mkdir(path)\n",
    "        if not os.path.isfile(path + str(city) + '/{}_map.csv'.format(city)) or update_data == True:\n",
    "        \n",
    "            # run main script\n",
    "            city_map_gdf, merged_gdf = merge_gdfs(city)\n",
    "\n",
    "            #print top 10 categories for each, just for the heck of it\n",
    "            print_top(city, merged_gdf, 10)\n",
    "            print()\n",
    "\n",
    "            # save to folder\n",
    "            if not os.path.isdir(path + str(city)):\n",
    "                os.mkdir(path + str(city))\n",
    "            city_map_gdf.geometry.to_file(path + str(city) + '/map_geo_{}.shp'.format(city))\n",
    "            map_df = pd.DataFrame(city_map_gdf.values, columns=city_map_gdf.columns)\n",
    "            map_df.to_csv(path + str(city) + '/{}_map.csv'.format(city), encoding='utf-8', index=False)\n",
    "            merged_gdf.geometry.to_file(path + str(city) + '/data_geo_{}.shp'.format(city))\n",
    "            data_df = pd.DataFrame(merged_gdf.values, columns=merged_gdf.columns)\n",
    "            data_df.to_csv(path + str(city) + '/{}_data.csv'.format(city), encoding='utf-8', index=False)\n",
    "               \n",
    "        else:\n",
    "            print(str(city) + ' is already saved as a file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_data(city):\n",
    "    '''\n",
    "    reads in files\n",
    "    '''\n",
    "    path             = 'coffee_data/'\n",
    "    crs              = {'init': 'epsg:4326'}\n",
    "    \n",
    "    def lon_lat_str_to_tuple(string):\n",
    "        '''\n",
    "        because coords are converted from tuple to string when \n",
    "        '''\n",
    "        string = string.split(', ')\n",
    "        lon = float(string[0].split('(')[1])\n",
    "        lat = float(string[1].split(')')[0])\n",
    "        return (lon, lat)\n",
    "    \n",
    "    # read in map\n",
    "    map_df           = pd.read_csv(path + str(city) + '/{}_map.csv'.format(city))\n",
    "    map_df_geo       = gpd.read_file(path + str(city) + '/map_geo_{}.shp'.format(city))\n",
    "    map_df.geometry  = map_df_geo.geometry\n",
    "    map_gdf          = gpd.GeoDataFrame(map_df, crs=crs, geometry=map_df.geometry)\n",
    "    map_gdf.coords   = map_gdf.coords.apply(lambda x: lon_lat_str_to_tuple(x))\n",
    "    \n",
    "    # read in data\n",
    "    data_df          = pd.read_csv(path + str(city) + '/{}_data.csv'.format(city))\n",
    "    data_df_geo      = gpd.read_file(path + str(city) + '/data_geo_{}.shp'.format(city))\n",
    "    data_df.geometry = data_df_geo.geometry\n",
    "    data_gdf         = gpd.GeoDataFrame(data_df, crs=crs, geometry=data_df.geometry)\n",
    "\n",
    "    return map_gdf, data_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def megalist(list_of_cities):\n",
    "    \n",
    "    if len(list_of_cities) == 0:\n",
    "        print('no cities provided')\n",
    "        return\n",
    "    \n",
    "    # make base dfs\n",
    "    if not os.path.isfile(path + str(list_of_cities[0]) + '/{}_map.csv'.format(list_of_cities[0])):\n",
    "        save_files([list_of_cities[0]])\n",
    "    mega_map, mega_data = read_in_data(list_of_cities[0])\n",
    "    \n",
    "    if len(list_of_cities) == 1:\n",
    "        return mega_map, mega_data\n",
    "    \n",
    "    for city in list_of_cities[1:]:\n",
    "        if not os.path.isfile(path + str(city) + '/{}_map.csv'.format(city)):\n",
    "            save_files([city])\n",
    "        temp_map, temp_data = read_in_data(city)\n",
    "        mega_map  = gpd.GeoDataFrame(pd.concat([mega_map, temp_map], ignore_index=True))\n",
    "        mega_data = gpd.GeoDataFrame(pd.concat([mega_data, temp_data], ignore_index=True))\n",
    "        \n",
    "    if not os.path.isdir(path + 'COFFEE'):\n",
    "        os.mkdir(path + 'COFFEE')\n",
    "    # save map data\n",
    "    mega_map.geometry.to_file(path + 'COFFEE' + '/map_geo_{}.shp'.format(city))\n",
    "    map_df = pd.DataFrame(mega_map.values, columns=mega_map.columns)\n",
    "    map_df.to_csv(path + 'COFFEE' + '/{}_map.csv'.format('COFFEE'), encoding='utf-8', index=False)\n",
    "    # save store data\n",
    "    mega_data.geometry.to_file(path + 'COFFEE' + '/data_geo_{}.shp'.format(city))\n",
    "    data_df = pd.DataFrame(mega_data.values, columns=mega_data.columns)\n",
    "    data_df.to_csv(path + 'COFFEE' + '/{}_data.csv'.format('COFFEE'), encoding='utf-8', index=False)\n",
    "    \n",
    "    return mega_map, mega_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mega_map, mega_data = megalist(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store_Name</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Location</th>\n",
       "      <th>Zip_Code</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_Count</th>\n",
       "      <th>geometry</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>...</th>\n",
       "      <th>chain</th>\n",
       "      <th>strictly_coffee</th>\n",
       "      <th>coffee_is_cat</th>\n",
       "      <th>breakfast_and_brunch</th>\n",
       "      <th>bakeries</th>\n",
       "      <th>diner</th>\n",
       "      <th>deli</th>\n",
       "      <th>ice_cream_and_froyo</th>\n",
       "      <th>juice_and_smoothie</th>\n",
       "      <th>primary_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ébrìk Coffee Room</td>\n",
       "      <td>['Coffee &amp; Tea', 'Bakeries']</td>\n",
       "      <td>(33.755247750486298, -84.388165147831302)</td>\n",
       "      <td>30303.0</td>\n",
       "      <td>$</td>\n",
       "      <td>4.5</td>\n",
       "      <td>260</td>\n",
       "      <td>POINT (-84.3881651478313 33.7552477504863)</td>\n",
       "      <td>GA</td>\n",
       "      <td>Fulton</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>bakeries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cafe Lucia</td>\n",
       "      <td>['Coffee &amp; Tea', 'Bagels', 'Juice Bars &amp; Smoot...</td>\n",
       "      <td>(33.755814000000001, -84.389904000000001)</td>\n",
       "      <td>30303.0</td>\n",
       "      <td>$</td>\n",
       "      <td>4.5</td>\n",
       "      <td>65</td>\n",
       "      <td>POINT (-84.389904 33.755814)</td>\n",
       "      <td>GA</td>\n",
       "      <td>Fulton</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>juice_and_smoothie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Condesa Coffee</td>\n",
       "      <td>['Coffee &amp; Tea', 'Breakfast &amp; Brunch']</td>\n",
       "      <td>(33.7553100585938, -84.382820129394503)</td>\n",
       "      <td>30303.0</td>\n",
       "      <td>$</td>\n",
       "      <td>4.0</td>\n",
       "      <td>39</td>\n",
       "      <td>POINT (-84.3828201293945 33.7553100585938)</td>\n",
       "      <td>GA</td>\n",
       "      <td>Fulton</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>breakfast_and_brunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Panbury's Pie Café</td>\n",
       "      <td>['British', 'Coffee &amp; Tea', 'Bakeries']</td>\n",
       "      <td>(33.760224600000001, -84.387175900000003)</td>\n",
       "      <td>30303.0</td>\n",
       "      <td>$</td>\n",
       "      <td>4.5</td>\n",
       "      <td>69</td>\n",
       "      <td>POINT (-84.3871759 33.7602246)</td>\n",
       "      <td>GA</td>\n",
       "      <td>Fulton</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>bakeries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THRIVE Farmers Coffee</td>\n",
       "      <td>['Coffee &amp; Tea']</td>\n",
       "      <td>(33.770229999999998, -84.388149999999996)</td>\n",
       "      <td>30308.0</td>\n",
       "      <td>$</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>POINT (-84.38815 33.77023)</td>\n",
       "      <td>GA</td>\n",
       "      <td>Fulton</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>strictly_coffee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Store_Name                                         Categories  \\\n",
       "0      Ébrìk Coffee Room                       ['Coffee & Tea', 'Bakeries']   \n",
       "1             Cafe Lucia  ['Coffee & Tea', 'Bagels', 'Juice Bars & Smoot...   \n",
       "2         Condesa Coffee             ['Coffee & Tea', 'Breakfast & Brunch']   \n",
       "3     Panbury's Pie Café            ['British', 'Coffee & Tea', 'Bakeries']   \n",
       "4  THRIVE Farmers Coffee                                   ['Coffee & Tea']   \n",
       "\n",
       "                                    Location  Zip_Code Price  Rating  \\\n",
       "0  (33.755247750486298, -84.388165147831302)   30303.0     $     4.5   \n",
       "1  (33.755814000000001, -84.389904000000001)   30303.0     $     4.5   \n",
       "2    (33.7553100585938, -84.382820129394503)   30303.0     $     4.0   \n",
       "3  (33.760224600000001, -84.387175900000003)   30303.0     $     4.5   \n",
       "4  (33.770229999999998, -84.388149999999996)   30308.0     $     4.0   \n",
       "\n",
       "   Review_Count                                    geometry State  County  \\\n",
       "0           260  POINT (-84.3881651478313 33.7552477504863)    GA  Fulton   \n",
       "1            65                POINT (-84.389904 33.755814)    GA  Fulton   \n",
       "2            39  POINT (-84.3828201293945 33.7553100585938)    GA  Fulton   \n",
       "3            69              POINT (-84.3871759 33.7602246)    GA  Fulton   \n",
       "4             2                  POINT (-84.38815 33.77023)    GA  Fulton   \n",
       "\n",
       "           ...           chain strictly_coffee  coffee_is_cat  \\\n",
       "0          ...           False           False           True   \n",
       "1          ...           False           False           True   \n",
       "2          ...           False           False           True   \n",
       "3          ...           False           False           True   \n",
       "4          ...           False            True           True   \n",
       "\n",
       "   breakfast_and_brunch bakeries  diner   deli ice_cream_and_froyo  \\\n",
       "0                 False     True  False  False               False   \n",
       "1                 False    False  False  False               False   \n",
       "2                  True    False  False  False               False   \n",
       "3                 False     True  False  False               False   \n",
       "4                 False    False  False  False               False   \n",
       "\n",
       "  juice_and_smoothie      primary_category  \n",
       "0              False              bakeries  \n",
       "1               True    juice_and_smoothie  \n",
       "2              False  breakfast_and_brunch  \n",
       "3              False              bakeries  \n",
       "4              False       strictly_coffee  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mega_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f34023e9e80>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6IAAAGdCAYAAAAIS87WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f340273f780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mega_map.plot(figsize=(16,16))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PUI2016_Python3",
   "language": "python",
   "name": "pui2016_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
